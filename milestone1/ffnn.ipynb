{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "08876914b93de310088a782f60f6c6abc8e6f6e29f02ef0079734cfa98a8305c"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Tugas Besar Machine Learning Milestone 1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Catatan untuk siapapun yang bikin input file untuk dibuat ke parameter"
   ]
  },
  {
   "source": [
    "Struktur data untuk array\n",
    "\n",
    "\n",
    "Sedikit penjelasan untuk parameter  \n",
    "W1 menyimpan semua bobot untuk layer 1  \n",
    "Wn menyimpan semua bobot untuk layer n\n",
    "\n",
    "Untuk memanggil bobot di layer 1 dengan dari x1  ke h1  \n",
    "`parameter['W1'][0][0]`  \n",
    "  \n",
    "Untuk memanggil bias di layer 1  ke-1  \n",
    "`parameter['b1'][0]`\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME : Delete pas kumpul\n",
    "\n",
    "# Untuk keperluan testing\n",
    "\n",
    "def initialize_parameters(layers_dims):\n",
    "    np.random.seed(69)               \n",
    "    parameters = {}\n",
    "    L = len(layers_dims)\n",
    "\n",
    "    for l in range(1, L):           \n",
    "        parameters[\"W\" + str(l)] = np.random.randn(\n",
    "            layers_dims[l], layers_dims[l - 1]) * 0.01\n",
    "        parameters[\"b\" + str(l)] = np.zeros((layers_dims[l], 1))\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'W1': array([[ 0.00915507, -0.00603542],\n       [ 0.01162295, -0.006014  ]]), 'b1': array([[0.],\n       [0.]]), 'W2': array([[-0.01597486,  0.00397726]]), 'b2': array([[0.]])}\n4\n[[ 0.00915507 -0.00603542]\n [ 0.01162295 -0.006014  ]]\n"
     ]
    }
   ],
   "source": [
    "# FIXME : Delete pas kumpul\n",
    "\n",
    "parameters = initialize_parameters([2,2,1])\n",
    "print(parameters)\n",
    "print(len(parameters))\n",
    "print(parameters['W1'])"
   ]
  },
  {
   "source": [
    "## Fungsi Parameter"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_parameter(parameter):\n",
    "    L = len(parameter) // 2\n",
    "\n",
    "    for i in range(0, L):\n",
    "        print('Layer ke ' + str(i+1) + \" :\")\n",
    "        print(\"W\" + str(i+1) + \" = \", parameter[\"W\" + str(i+1)])\n",
    "        print(\"b\" + str(i+1) + \" = \", parameter[\"b\" + str(i+1)])\n",
    "\n",
    "        # for j in range(0, len(parameter[\"W\" + str(i+1)])):\n",
    "        #     for k in range(0, len(parameter[\"W\" + str(i+1)][j])):\n",
    "        #         print('W' + str(j+1) + str(k+1) + \" = \", parameter[\"W\" + str(i+1)][j][k])"
   ]
  },
  {
   "source": [
    "## Fungsi-fungsi aktivasi"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(c, Z):\n",
    "    A = np.multiply(c, Z)\n",
    "    return A, Z\n",
    "\n",
    "def sigmoid(Z):\n",
    "    A = 1 / (1 + np.exp(-Z))\n",
    "    return A, Z\n",
    "\n",
    "def relu(Z):\n",
    "    A = np.maximum(0, Z)\n",
    "    return A, Z\n",
    "\n",
    "def softmax(Z):\n",
    "    e = np.exp(Z)\n",
    "    return e/e.sum(), Z\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[20, 20], [-20, 20]]\n[[20, 20]]\n[[-10], [30]]\n[[-30]]\n4\n{'W1': [[20, 20], [-20, 20]], 'W2': [[20, 20]], 'b1': [[-10], [30]], 'b2': [[-30]]}\n[[20, 20], [-20, 20]]\n<class 'list'>\n0.9525741268224334\n3\n12\n1.0\n"
     ]
    }
   ],
   "source": [
    "# testing activation function\n",
    "test_parameter = {}\n",
    "file = open(\"demofile.txt\", \"r\")\n",
    "switch = False\n",
    "i = 0\n",
    "for lines in file:\n",
    "    lines = lines.replace('\\n','')\n",
    "    if lines == \"bias\":\n",
    "        switch = True\n",
    "        i = 0\n",
    "    else:\n",
    "        i=i+1\n",
    "        #readline = re.split('\\],',readline)\n",
    "        reader = re.split('\\],\\s*',lines)\n",
    "        for itter in range(len(reader)):\n",
    "            reader[itter] = reader[itter].replace('[','')\n",
    "            reader[itter] = reader[itter].replace(']','')\n",
    "            reader[itter] = re.split(',\\s',reader[itter])\n",
    "            for seconditter in range(len(reader[itter])):\n",
    "                reader[itter][seconditter] = int(reader[itter][seconditter])\n",
    "        print(reader)\n",
    "        #print(re.split('\\],\\s',lines))\n",
    "        if (not switch):\n",
    "            test_parameter[str('W'+str(i))] = reader\n",
    "        else:\n",
    "            test_parameter[str('b'+str(i))] = reader\n",
    "#end of reader    \n",
    "\"\"\" test_parameter['W1'] = [[20, 20], [-20, 20]]\n",
    "test_parameter['W2'] = [[20, 20]]\n",
    "test_parameter['b1'] = [[-10],[30]]\n",
    "test_parameter['b2'] = [[-30]] \"\"\"\n",
    "\n",
    "print(len(test_parameter))\n",
    "\n",
    "print(test_parameter)\n",
    "print(test_parameter['W1'])\n",
    "print(type(test_parameter['W1']))\n",
    "\n",
    "Z = [3, 7, 12]\n",
    "\n",
    "a, aa = sigmoid(3)\n",
    "b, bb = relu(3)\n",
    "c, cc = linear(3)\n",
    "d, dd = softmax(3)\n",
    "\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "print(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(A_prev, W, b):\n",
    "    Z = np.dot(W, A_prev) + b\n",
    "    cache = (A_prev, W, b)\n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_forward(A_prev, W, b, activation_fn):\n",
    "\n",
    "    Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "\n",
    "    if activation_fn == \"linear\":\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "        Z = linear_forward(A_prev, W, b)\n",
    "        A = linear(1, Z)\n",
    "\n",
    "    elif activation_fn == \"sigmoid\":\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "\n",
    "    elif activation_fn == \"relu\":\n",
    "        A, activation_cache = relu(Z)\n",
    "\n",
    "    elif activation_fn == \"softmax\":\n",
    "        A, activation_cache = softmax(Z)\n",
    "    \n",
    "    else :\n",
    "        raise Exception(\"Activation Function unknown\")\n",
    "        raise Exception(\"activation function unknown\")\n",
    "\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_forward(X, parameters, hidden_layers_activation_fn=\"relu\"):\n",
    "    A = X                                               \n",
    "    L = len(parameters) // 2       \n",
    "\n",
    "    for l in range(1, L):\n",
    "        # print(l)\n",
    "        A_prev = A\n",
    "        A = linear_activation_forward(A_prev, parameters[\"W\" + str(l)], parameters[\"b\" + str(l)], activation_fn=hidden_layers_activation_fn)\n",
    "        # print(A)\n",
    "\n",
    "    assert A.shape == (W.shape[0], A_prev.shape[1])\n",
    "\n",
    "    cache = (linear_cache, activation_cache)\n",
    "    return A, cache\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def L_model_forward(X, parameters, hidden_layers_activation_fn=\"relu\"):\n",
    "#     A = X                           \n",
    "#     caches = []                     \n",
    "#     L = len(parameters) // 2        \n",
    "\n",
    "#     for l in range(1, L):\n",
    "#         A_prev = A\n",
    "#         A, cache = linear_activation_forward(\n",
    "#             A_prev, parameters[\"W\" + str(l)], parameters[\"b\" + str(l)],\n",
    "#             activation_fn=hidden_layers_activation_fn)\n",
    "#         caches.append(cache)\n",
    "\n",
    "#     AL, cache = linear_activation_forward(\n",
    "#         A, parameters[\"W\" + str(L)], parameters[\"b\" + str(L)],\n",
    "#         activation_fn=\"sigmoid\")\n",
    "#     caches.append(cache)\n",
    "\n",
    "#     assert AL.shape == (1, X.shape[1])\n",
    "#     return AL, caches"
   ]
  },
  {
   "source": [
    "meh, lupakan ini..\n",
    "ternyata tugasnya bukan learning tapi baca model trus eksekusi"
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "4\n{'W1': [[20, 20], [-20, 20]], 'b1': [[-10], [30]], 'W2': [[20, 20]], 'b2': [[-30]]}\n[[20, 20], [-20, 20]]\n"
     ]
    }
   ],
   "source": [
    "# FIXME : Delete pas kumpul\n",
    "\n",
    "test_parameter = {}\n",
    "test_parameter['W1'] = [[20, 20], [-20, 20]]\n",
    "test_parameter['b1'] = [[-10],[30]]\n",
    "test_parameter['W2'] = [[20, 20]]\n",
    "test_parameter['b2'] = [[-30]]\n",
    "\n",
    "print(len(test_parameter))\n",
    "\n",
    "print(test_parameter)\n",
    "print(test_parameter['W1'])"
   ]
  },
  {
   "source": [
    "tes fungsi  \n",
    "\n",
    "Dari soal slide kuliah"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def initialize_parameters(layers_dims):\n",
    "#     np.random.seed(1)               \n",
    "#     parameters = {}\n",
    "#     L = len(layers_dims)            \n",
    "# FIXME : Delete pas kumpul\n",
    "\n",
    "X = [0,0]\n",
    "aa = L_model_forward(X, test_parameter, \"sigmoid\")\n",
    "print(aa)\n",
    "\n",
    "X2 = [0,1]\n",
    "bb = L_model_forward(X2, test_parameter, \"sigmoid\")\n",
    "print(bb)\n",
    "\n",
    "#     for l in range(1, L):           \n",
    "#         parameters[\"W\" + str(l)] = np.random.randn(\n",
    "#             layers_dims[l], layers_dims[l - 1]) * 0.01\n",
    "#         parameters[\"b\" + str(l)] = np.zeros((layers_dims[l], 1))\n",
    "\n",
    "#         assert parameters[\"W\" + str(l)].shape == (\n",
    "#             layers_dims[l], layers_dims[l - 1])\n",
    "#         assert parameters[\"b\" + str(l)].shape == (layers_dims[l], 1)\n",
    "    \n",
    "#     return parameters"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Layer ke 1 :\nW1 =  [[20, 20], [-20, 20]]\nb1 =  [[-10], [30]]\nLayer ke 2 :\nW2 =  [[20, 20]]\nb2 =  [[-30]]\n"
     ]
    }
   ],
   "source": [
    "# FIXME : Delete pas kumpul\n",
    "\n",
    "print_parameter(test_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "08876914b93de310088a782f60f6c6abc8e6f6e29f02ef0079734cfa98a8305c"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Tugas Besar Machine Learning Milestone 1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "source": [
    "## Fungsi-fungsi aktivasi"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(Z):\n",
    "    c = 4\n",
    "    A = np.multiply(c, Z)\n",
    "    return A, Z\n",
    "\n",
    "def sigmoid(Z):\n",
    "    A = 1 / (1 + np.exp(-Z))\n",
    "    return A, Z\n",
    "\n",
    "def relu(Z):\n",
    "    A = np.maximum(0, Z)\n",
    "    return A, Z\n",
    "\n",
    "def softmax(Z):\n",
    "    e = np.exp(Z)\n",
    "    return e/e.sum(), Z\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[20, 20], [-20, 20]]\n[[20, 20]]\n[[-10], [30]]\n[[-30]]\n4\n{'W1': [[20, 20], [-20, 20]], 'W2': [[20, 20]], 'b1': [[-10], [30]], 'b2': [[-30]]}\n[[20, 20], [-20, 20]]\n<class 'list'>\n0.9525741268224334\n3\n12\n1.0\n"
     ]
    }
   ],
   "source": [
    "# testing activation function\n",
    "test_parameter = {}\n",
    "file = open(\"demofile.txt\", \"r\")\n",
    "switch = False\n",
    "i = 0\n",
    "for lines in file:\n",
    "    lines = lines.replace('\\n','')\n",
    "    if lines == \"bias\":\n",
    "        switch = True\n",
    "        i = 0\n",
    "    else:\n",
    "        i=i+1\n",
    "        #readline = re.split('\\],',readline)\n",
    "        reader = re.split('\\],\\s*',lines)\n",
    "        for itter in range(len(reader)):\n",
    "            reader[itter] = reader[itter].replace('[','')\n",
    "            reader[itter] = reader[itter].replace(']','')\n",
    "            reader[itter] = re.split(',\\s',reader[itter])\n",
    "            for seconditter in range(len(reader[itter])):\n",
    "                reader[itter][seconditter] = int(reader[itter][seconditter])\n",
    "        print(reader)\n",
    "        #print(re.split('\\],\\s',lines))\n",
    "        if (not switch):\n",
    "            test_parameter[str('W'+str(i))] = reader\n",
    "        else:\n",
    "            test_parameter[str('b'+str(i))] = reader\n",
    "#end of reader    \n",
    "\"\"\" test_parameter['W1'] = [[20, 20], [-20, 20]]\n",
    "test_parameter['W2'] = [[20, 20]]\n",
    "test_parameter['b1'] = [[-10],[30]]\n",
    "test_parameter['b2'] = [[-30]] \"\"\"\n",
    "\n",
    "print(len(test_parameter))\n",
    "\n",
    "print(test_parameter)\n",
    "print(test_parameter['W1'])\n",
    "print(type(test_parameter['W1']))\n",
    "\n",
    "Z = [3, 7, 12]\n",
    "\n",
    "a, aa = sigmoid(3)\n",
    "b, bb = relu(3)\n",
    "c, cc = linear(3)\n",
    "d, dd = softmax(3)\n",
    "\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "print(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(A_prev, W, b):\n",
    "    Z = np.dot(W, A_prev) + b\n",
    "    cache = (A_prev, W, b)\n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_forward(A_prev, W, b, activation_fn):\n",
    "\n",
    "    Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "\n",
    "    if activation_fn == \"linear\":\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "\n",
    "    elif activation_fn == \"sigmoid\":\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "\n",
    "    elif activation_fn == \"relu\":\n",
    "        A, activation_cache = relu(Z)\n",
    "\n",
    "    elif activation_fn == \"softmax\":\n",
    "        A, activation_cache = softmax(Z)\n",
    "    \n",
    "    else :\n",
    "        raise Exception(\"Activation Function unknown\")\n",
    "\n",
    "    assert A.shape == (W.shape[0], A_prev.shape[1])\n",
    "\n",
    "    cache = (linear_cache, activation_cache)\n",
    "    return A, cache\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def L_model_forward(X, parameters, hidden_layers_activation_fn=\"relu\"):\n",
    "#     A = X                           \n",
    "#     caches = []                     \n",
    "#     L = len(parameters) // 2        \n",
    "\n",
    "#     for l in range(1, L):\n",
    "#         A_prev = A\n",
    "#         A, cache = linear_activation_forward(\n",
    "#             A_prev, parameters[\"W\" + str(l)], parameters[\"b\" + str(l)],\n",
    "#             activation_fn=hidden_layers_activation_fn)\n",
    "#         caches.append(cache)\n",
    "\n",
    "#     AL, cache = linear_activation_forward(\n",
    "#         A, parameters[\"W\" + str(L)], parameters[\"b\" + str(L)],\n",
    "#         activation_fn=\"sigmoid\")\n",
    "#     caches.append(cache)\n",
    "\n",
    "#     assert AL.shape == (1, X.shape[1])\n",
    "#     return AL, caches"
   ]
  },
  {
   "source": [
    "meh, lupakan ini..\n",
    "ternyata tugasnya bukan learning tapi baca model trus eksekusi"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def initialize_parameters(layers_dims):\n",
    "#     np.random.seed(1)               \n",
    "#     parameters = {}\n",
    "#     L = len(layers_dims)            \n",
    "\n",
    "#     for l in range(1, L):           \n",
    "#         parameters[\"W\" + str(l)] = np.random.randn(\n",
    "#             layers_dims[l], layers_dims[l - 1]) * 0.01\n",
    "#         parameters[\"b\" + str(l)] = np.zeros((layers_dims[l], 1))\n",
    "\n",
    "#         assert parameters[\"W\" + str(l)].shape == (\n",
    "#             layers_dims[l], layers_dims[l - 1])\n",
    "#         assert parameters[\"b\" + str(l)].shape == (layers_dims[l], 1)\n",
    "    \n",
    "#     return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
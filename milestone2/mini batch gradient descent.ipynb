{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "08876914b93de310088a782f60f6c6abc8e6f6e29f02ef0079734cfa98a8305c"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Tugas Besar Machine Learning Milestone 2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "source": [
    "## Load dataset iris"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                5.1               3.5                1.4               0.2\n",
       "1                4.9               3.0                1.4               0.2\n",
       "2                4.7               3.2                1.3               0.2\n",
       "3                4.6               3.1                1.5               0.2\n",
       "4                5.0               3.6                1.4               0.2"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sepal length (cm)</th>\n      <th>sepal width (cm)</th>\n      <th>petal length (cm)</th>\n      <th>petal width (cm)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.1</td>\n      <td>3.5</td>\n      <td>1.4</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>3.6</td>\n      <td>1.4</td>\n      <td>0.2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets,model_selection,metrics\n",
    "iris = datasets.load_iris()\n",
    "iris = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "iris.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "X_train = X\n",
    "y_train = y\n",
    "# print(y_train)\n",
    "# print(X_train)"
   ]
  },
  {
   "source": [
    "## Fungsi utilitas"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(25)\n",
    "\n",
    "def rand(a, b):\n",
    "    return (b-a)*random.random() + a\n",
    "\n",
    "def makeMatrix(I, J, fill=0.0):\n",
    "    m = []\n",
    "    for i in range(I):\n",
    "        m.append([fill]*J)\n",
    "    return m"
   ]
  },
  {
   "source": [
    "## Fungsi-fungsi aktivasi"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(x):\n",
    "    return x\n",
    "\n",
    "def dlinear(y):\n",
    "    return 1.0\n",
    "\n",
    "def sigmoid(x):\n",
    "    return math.tanh(x)\n",
    "\n",
    "def dsigmoid(y):\n",
    "    return 1.0 - y**2\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0.0,x)\n",
    "\n",
    "def drelu(y):\n",
    "    if y > 0.0 :\n",
    "        return 1.0\n",
    "    else :\n",
    "        return 0.0\n",
    "\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x)\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "def dsoftmax(y):\n",
    "    \"\"\" \n",
    "    if( = targetclass):\n",
    "        return y\n",
    "    else:\n",
    "        return -1 #apalah \"\"\"\n",
    "    pass"
   ]
  },
  {
   "source": [
    "## Kelas Neural Network\n",
    "note : kode ditulis ulang dari milestone 1 karena representasi bobotnya terlalu susah buat dipake hitung"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, ni, nh, no):\n",
    "        self.ni = ni + 1\n",
    "        self.nh = nh\n",
    "        self.no = no\n",
    "\n",
    "        self.ai = [1.0]*self.ni\n",
    "        self.ah = [1.0]*self.nh\n",
    "        self.ao = [1.0]*self.no\n",
    "\n",
    "        self.wi = makeMatrix(self.ni, self.nh)\n",
    "        self.wo = makeMatrix(self.nh, self.no)\n",
    "\n",
    "        self.activation_function = \"sigmoid\"\n",
    "\n",
    "        # init bobot neural network\n",
    "        for i in range(self.ni):\n",
    "            for j in range(self.nh):\n",
    "                self.wi[i][j] = rand(-0.4, 0.4)\n",
    "        for j in range(self.nh):\n",
    "            for k in range(self.no):\n",
    "                self.wo[j][k] = rand(-5.0, 5.0)\n",
    "\n",
    "\n",
    "    def activate(self, inputs):\n",
    "        assert len(inputs) == self.ni-1, \"masukan input salah\"\n",
    "\n",
    "        # aktivasi input layer\n",
    "        for i in range(self.ni-1):\n",
    "            self.ai[i] = inputs[i]\n",
    "\n",
    "        # aktivasi \n",
    "        for j in range(self.nh):\n",
    "            sum = 0.0\n",
    "            for i in range(self.ni):\n",
    "                sum = sum + self.ai[i] * self.wi[i][j]\n",
    "            self.ah[j] = sigmoid(sum)\n",
    "\n",
    "        # output activations\n",
    "        for k in range(self.no):\n",
    "            sum = 0.0\n",
    "            for j in range(self.nh):\n",
    "                sum = sum + self.ah[j] * self.wo[j][k]\n",
    "            self.ao[k] = sigmoid(sum)\n",
    "\n",
    "        return self.ao[:]\n",
    "\n",
    "\n",
    "    def backPropagate(self, targets, learning_rate, activation_function):\n",
    "        assert len(targets) == self.no, \"masukan target salah\"\n",
    "\n",
    "        output_deltas = [0.0] * self.no\n",
    "        for k in range(self.no):\n",
    "            error = targets[k]-self.ao[k]\n",
    "            output_deltas[k] = dsigmoid(self.ao[k]) * error\n",
    "\n",
    "        hidden_deltas = [0.0] * self.nh\n",
    "        for j in range(self.nh):\n",
    "            error = 0.0\n",
    "            for k in range(self.no):\n",
    "                error = error + output_deltas[k]*self.wo[j][k]\n",
    "            hidden_deltas[j] = dsigmoid(self.ah[j]) * error\n",
    "\n",
    "        for j in range(self.nh):\n",
    "            for k in range(self.no):\n",
    "                w_delta = output_deltas[k]*self.ah[j]\n",
    "                self.wo[j][k] = self.wo[j][k] + learning_rate*w_delta\n",
    "\n",
    "        for i in range(self.ni):\n",
    "            for j in range(self.nh):\n",
    "                w_delta = hidden_deltas[j]*self.ai[i]\n",
    "                self.wi[i][j] = self.wi[i][j] + learning_rate*w_delta\n",
    "\n",
    "        error = 0.0\n",
    "        if(activation_function != \"softmax\"):\n",
    "            for k in range(len(targets)):\n",
    "                error = error + 0.5*(targets[k]-self.ao[k])**2\n",
    "        else:\n",
    "            # error function softmax\n",
    "            for k in range(len(targets)):\n",
    "                error = error -log(softmax(targets[k]))\n",
    "        return error\n",
    "\n",
    "\n",
    "    def test(self, X_test):\n",
    "        for x in X_test:\n",
    "            print(x, '->', self.activate(x))\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        prediction = []\n",
    "        for i in range(len(X_test)):\n",
    "            prediction.append(self.activate(X_test[i]))\n",
    "        return prediction\n",
    "\n",
    "    def createMiniBatches(self, X_train, y_train, batch_size):\n",
    "        mini_batches = []\n",
    "        data = np.hstack((X_train, y_train))\n",
    "        np.random.shuffle(data)\n",
    "        n_minibatches = data.shape[0] // batch_size\n",
    "\n",
    "        for i in range(n_minibatches + 1):\n",
    "            mini_batch = data[i * batch_size:(i + 1)*batch_size, :]\n",
    "            X_mini = mini_batch[:, :-1]\n",
    "            Y_mini = mini_batch[:, -1].reshape((-1, 1))\n",
    "            mini_batches.append((X_mini, Y_mini))\n",
    "        if data.shape[0] % batch_size != 0:\n",
    "            mini_batch = data[i * batch_size:data.shape[0]]\n",
    "            X_mini = mini_batch[:, :-1]\n",
    "            Y_mini = mini_batch[:, -1].reshape((-1, 1))\n",
    "            mini_batches.append((X_mini, Y_mini))\n",
    "        return mini_batches\n",
    "\n",
    "    def train(self, X_train, y_train, iterations=30, learning_rate=0.01, error_treshold = 0.01, activation_function=\"sigmoid\", batch_size = 10):\n",
    "        # N: learning rate\n",
    "        self.activation_function = activation_function\n",
    "        for i in range(0, iterations):\n",
    "            error = 0.0\n",
    "            mini_batches = self.createMiniBatches(X_train, y_train, batch_size)\n",
    "            for mini_batch in mini_batches:\n",
    "                error = 0.0\n",
    "                for j in range(0, len(X_train)):\n",
    "                    inputs = X_train[j]\n",
    "                    targets = y_train[j]\n",
    "                    self.activate(inputs)\n",
    "                    error = error + self.backPropagate(targets, learning_rate, activation_function)\n",
    "\n",
    "                if i % 10 == 0:\n",
    "                    print('error %-.5f' % error)\n",
    "\n",
    "                if error < error_treshold:\n",
    "                    print('final error %-.5f' % error)\n",
    "                    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2]]\n",
      "error 49.99939\n",
      "error 49.99938\n",
      "error 49.99937\n",
      "error 49.99935\n",
      "error 49.99934\n",
      "error 49.99932\n",
      "error 49.99930\n",
      "error 49.99928\n",
      "error 49.99927\n",
      "error 49.99925\n",
      "error 49.99923\n",
      "error 49.99920\n",
      "error 49.99918\n",
      "error 49.99915\n",
      "error 49.99913\n",
      "error 49.99910\n",
      "error 25.03421\n",
      "error 25.03391\n",
      "error 25.03363\n",
      "error 25.03334\n",
      "error 25.03307\n",
      "error 25.03280\n",
      "error 25.03253\n",
      "error 25.03227\n",
      "error 25.03201\n",
      "error 25.03175\n",
      "error 25.03150\n",
      "error 25.03126\n",
      "error 25.03102\n",
      "error 25.03078\n",
      "error 25.03055\n",
      "error 25.03032\n",
      "error 25.01518\n",
      "error 25.01513\n",
      "error 25.01509\n",
      "error 25.01504\n",
      "error 25.01499\n",
      "error 25.01494\n",
      "error 25.01490\n",
      "error 25.01485\n",
      "error 25.01481\n",
      "error 25.01476\n",
      "error 25.01472\n",
      "error 25.01467\n",
      "error 25.01463\n",
      "error 25.01458\n",
      "error 25.01454\n",
      "error 25.01449\n",
      "[5.1 3.5 1.4 0.2] -> [-0.0017714477113655596]\n",
      "[4.9 3.  1.4 0.2] -> [-0.0008804451637215458]\n",
      "[4.7 3.2 1.3 0.2] -> [-0.009742618025781342]\n",
      "[4.6 3.1 1.5 0.2] -> [0.012929666451884727]\n",
      "[5.  3.6 1.4 0.2] -> [0.002029632132851449]\n",
      "[5.4 3.9 1.7 0.4] -> [0.0053377792193019654]\n",
      "[4.6 3.4 1.4 0.3] -> [-0.0035158507638268456]\n",
      "[5.  3.4 1.5 0.2] -> [0.00022559092431413693]\n",
      "[4.4 2.9 1.4 0.2] -> [0.014078180477131308]\n",
      "[4.9 3.1 1.5 0.1] -> [0.005366672356588998]\n",
      "[5.4 3.7 1.5 0.2] -> [0.002705208803896292]\n",
      "[4.8 3.4 1.6 0.2] -> [0.007961270472982132]\n",
      "[4.8 3.  1.4 0.1] -> [-0.0012502806388423552]\n",
      "[4.3 3.  1.1 0.1] -> [-0.026647616356269815]\n",
      "[5.8 4.  1.2 0.2] -> [0.02071963720686484]\n",
      "[5.7 4.4 1.5 0.4] -> [0.0277979666854026]\n",
      "[5.4 3.9 1.3 0.4] -> [0.01104648993803791]\n",
      "[5.1 3.5 1.4 0.3] -> [-0.002584707668652038]\n",
      "[5.7 3.8 1.7 0.3] -> [0.0019593761795550567]\n",
      "[5.1 3.8 1.5 0.3] -> [0.00599443879472073]\n",
      "[5.4 3.4 1.7 0.2] -> [0.007641608984904649]\n",
      "[5.1 3.7 1.5 0.4] -> [0.0024753651268922547]\n",
      "[4.6 3.6 1.  0.2] -> [0.014863808798778782]\n",
      "[5.1 3.3 1.7 0.5] -> [0.029028699803608338]\n",
      "[4.8 3.4 1.9 0.2] -> [0.04829805537666875]\n",
      "[5.  3.  1.6 0.2] -> [0.025400455573835655]\n",
      "[5.  3.4 1.6 0.4] -> [0.010069771759066693]\n",
      "[5.2 3.5 1.5 0.2] -> [-0.0005369812194685051]\n",
      "[5.2 3.4 1.4 0.2] -> [-0.005105233733366316]\n",
      "[4.7 3.2 1.6 0.2] -> [0.019124023897570577]\n",
      "[4.8 3.1 1.6 0.2] -> [0.024062401634834415]\n",
      "[5.4 3.4 1.5 0.4] -> [-0.002155375971310288]\n",
      "[5.2 4.1 1.5 0.1] -> [0.029338247110995117]\n",
      "[5.5 4.2 1.4 0.2] -> [0.0332959776791757]\n",
      "[4.9 3.1 1.5 0.2] -> [0.007494555816965851]\n",
      "[5.  3.2 1.2 0.2] -> [-0.015329888459252696]\n",
      "[5.5 3.5 1.3 0.2] -> [-0.006307857490365737]\n",
      "[4.9 3.6 1.4 0.1] -> [0.004748437169859818]\n",
      "[4.4 3.  1.3 0.2] -> [-0.007274733201944383]\n",
      "[5.1 3.4 1.5 0.2] -> [-0.0005804630641463245]\n",
      "[5.  3.5 1.3 0.3] -> [-0.003361509352584654]\n",
      "[4.5 2.3 1.3 0.3] -> [0.06215428058102662]\n",
      "[4.4 3.2 1.3 0.2] -> [-0.010512173162807946]\n",
      "[5.  3.5 1.6 0.6] -> [0.012921949146846044]\n",
      "[5.1 3.8 1.9 0.4] -> [0.016227208618113487]\n",
      "[4.8 3.  1.4 0.3] -> [0.0038047043930212526]\n",
      "[5.1 3.8 1.6 0.2] -> [0.0067563430115804195]\n",
      "[4.6 3.2 1.4 0.2] -> [-0.0025145577018185865]\n",
      "[5.3 3.7 1.5 0.2] -> [0.0035611276843104055]\n",
      "[5.  3.3 1.4 0.2] -> [-0.00503360106373328]\n",
      "[7.  3.2 4.7 1.4] -> [0.9980536278594838]\n",
      "[6.4 3.2 4.5 1.5] -> [0.9985681260929664]\n",
      "[6.9 3.1 4.9 1.5] -> [0.9995096134610201]\n",
      "[5.5 2.3 4.  1.3] -> [0.9996967022839198]\n",
      "[6.5 2.8 4.6 1.5] -> [0.9995741678449486]\n",
      "[5.7 2.8 4.5 1.3] -> [0.9997738850615743]\n",
      "[6.3 3.3 4.7 1.6] -> [0.999400978701539]\n",
      "[4.9 2.4 3.3 1. ] -> [0.9951874172291937]\n",
      "[6.6 2.9 4.6 1.3] -> [0.9992503624396778]\n",
      "[5.2 2.7 3.9 1.4] -> [0.9992375856391004]\n",
      "[5.  2.  3.5 1. ] -> [0.9994111428077396]\n",
      "[5.9 3.  4.2 1.5] -> [0.9986417050428825]\n",
      "[6.  2.2 4.  1. ] -> [0.999275410118079]\n",
      "[6.1 2.9 4.7 1.4] -> [0.9997758069277342]\n",
      "[5.6 2.9 3.6 1.3] -> [0.9865479012190858]\n",
      "[6.7 3.1 4.4 1.4] -> [0.9964349603779858]\n",
      "[5.6 3.  4.5 1.5] -> [0.9997304530566886]\n",
      "[5.8 2.7 4.1 1. ] -> [0.9987316839377416]\n",
      "[6.2 2.2 4.5 1.5] -> [0.9999030515022848]\n",
      "[5.6 2.5 3.9 1.1] -> [0.9988315927651968]\n",
      "[5.9 3.2 4.8 1.8] -> [0.9998172857368995]\n",
      "[6.1 2.8 4.  1.3] -> [0.996223653193069]\n",
      "[6.3 2.5 4.9 1.5] -> [0.9999328162336629]\n",
      "[6.1 2.8 4.7 1.2] -> [0.9997932357241495]\n",
      "[6.4 2.9 4.3 1.3] -> [0.9979479135968117]\n",
      "[6.6 3.  4.4 1.4] -> [0.9977610437531098]\n",
      "[6.8 2.8 4.8 1.4] -> [0.9996586794973936]\n",
      "[6.7 3.  5.  1.7] -> [0.999815914794264]\n",
      "[6.  2.9 4.5 1.5] -> [0.9996382249135307]\n",
      "[5.7 2.6 3.5 1. ] -> [0.9839684732564956]\n",
      "[5.5 2.4 3.8 1.1] -> [0.9988348358931529]\n",
      "[5.5 2.4 3.7 1. ] -> [0.9979068135635633]\n",
      "[5.8 2.7 3.9 1.2] -> [0.9971979935950144]\n",
      "[6.  2.7 5.1 1.6] -> [0.9999512799968862]\n",
      "[5.4 3.  4.5 1.5] -> [0.99978108310725]\n",
      "[6.  3.4 4.5 1.6] -> [0.9989427475702494]\n",
      "[6.7 3.1 4.7 1.5] -> [0.9992032581591443]\n",
      "[6.3 2.3 4.4 1.3] -> [0.9997674097127142]\n",
      "[5.6 3.  4.1 1.3] -> [0.9984871164180674]\n",
      "[5.5 2.5 4.  1.3] -> [0.9994775425965347]\n",
      "[5.5 2.6 4.4 1.2] -> [0.9998343272681254]\n",
      "[6.1 3.  4.6 1.4] -> [0.9996076419404593]\n",
      "[5.8 2.6 4.  1.2] -> [0.9987038979203297]\n",
      "[5.  2.3 3.3 1. ] -> [0.9956629136176172]\n",
      "[5.6 2.7 4.2 1.3] -> [0.9995453059512578]\n",
      "[5.7 3.  4.2 1.2] -> [0.9987396682276533]\n",
      "[5.7 2.9 4.2 1.3] -> [0.9991112757503445]\n",
      "[6.2 2.9 4.3 1.3] -> [0.9986125585859476]\n",
      "[5.1 2.5 3.  1.1] -> [0.9604764016835821]\n",
      "[5.7 2.8 4.1 1.3] -> [0.9989359938665072]\n",
      "[6.3 3.3 6.  2.5] -> [0.9999681543681453]\n",
      "[5.8 2.7 5.1 1.9] -> [0.999961951311619]\n",
      "[7.1 3.  5.9 2.1] -> [0.9999639393354982]\n",
      "[6.3 2.9 5.6 1.8] -> [0.9999640772849785]\n",
      "[6.5 3.  5.8 2.2] -> [0.9999693099876907]\n",
      "[7.6 3.  6.6 2.1] -> [0.9999765001416185]\n",
      "[4.9 2.5 4.5 1.7] -> [0.9999525717018855]\n",
      "[7.3 2.9 6.3 1.8] -> [0.9999743996442035]\n",
      "[6.7 2.5 5.8 1.8] -> [0.9999818508711953]\n",
      "[7.2 3.6 6.1 2.5] -> [0.9999521199040486]\n",
      "[6.5 3.2 5.1 2. ] -> [0.9998692225092268]\n",
      "[6.4 2.7 5.3 1.9] -> [0.999960455574532]\n",
      "[6.8 3.  5.5 2.1] -> [0.9999476584306211]\n",
      "[5.7 2.5 5.  2. ] -> [0.9999719567207659]\n",
      "[5.8 2.8 5.1 2.4] -> [0.9999655858217242]\n",
      "[6.4 3.2 5.3 2.3] -> [0.9999339632533383]\n",
      "[6.5 3.  5.5 1.8] -> [0.9999492619518046]\n",
      "[7.7 3.8 6.7 2.2] -> [0.9999550641536955]\n",
      "[7.7 2.6 6.9 2.3] -> [0.9999886249216382]\n",
      "[6.  2.2 5.  1.5] -> [0.999977464873759]\n",
      "[6.9 3.2 5.7 2.3] -> [0.999951573632018]\n",
      "[5.6 2.8 4.9 2. ] -> [0.9999477324110534]\n",
      "[7.7 2.8 6.7 2. ] -> [0.9999818343783695]\n",
      "[6.3 2.7 4.9 1.8] -> [0.9999158951645415]\n",
      "[6.7 3.3 5.7 2.1] -> [0.9999453227215455]\n",
      "[7.2 3.2 6.  1.8] -> [0.9999527587034979]\n",
      "[6.2 2.8 4.8 1.8] -> [0.9998821221814225]\n",
      "[6.1 3.  4.9 1.8] -> [0.999881105959098]\n",
      "[6.4 2.8 5.6 2.1] -> [0.9999713288773009]\n",
      "[7.2 3.  5.8 1.6] -> [0.9999485169693616]\n",
      "[7.4 2.8 6.1 1.9] -> [0.9999722812934806]\n",
      "[7.9 3.8 6.4 2. ] -> [0.9999325496968606]\n",
      "[6.4 2.8 5.6 2.2] -> [0.9999724474349415]\n",
      "[6.3 2.8 5.1 1.5] -> [0.9999251829971785]\n",
      "[6.1 2.6 5.6 1.4] -> [0.9999770057926601]\n",
      "[7.7 3.  6.1 2.3] -> [0.9999640657651094]\n",
      "[6.3 3.4 5.6 2.4] -> [0.9999492353867738]\n",
      "[6.4 3.1 5.5 1.8] -> [0.9999442060569386]\n",
      "[6.  3.  4.8 1.8] -> [0.9998608254778723]\n",
      "[6.9 3.1 5.4 2.1] -> [0.9999228792116717]\n",
      "[6.7 3.1 5.6 2.4] -> [0.9999578384921641]\n",
      "[6.9 3.1 5.1 2.3] -> [0.9998591476202963]\n",
      "[5.8 2.7 5.1 1.9] -> [0.999961951311619]\n",
      "[6.8 3.2 5.9 2.3] -> [0.9999627494176243]\n",
      "[6.7 3.3 5.7 2.5] -> [0.9999553891882348]\n",
      "[6.7 3.  5.2 2.3] -> [0.9999239549088861]\n",
      "[6.3 2.5 5.  1.9] -> [0.9999550976730275]\n",
      "[6.5 3.  5.2 2. ] -> [0.9999238669625456]\n",
      "[6.2 3.4 5.4 2.3] -> [0.9999338781280009]\n",
      "[5.9 3.  5.1 1.8] -> [0.9999311501344308]\n"
     ]
    }
   ],
   "source": [
    "X_dataset, y_dataset = datasets.load_iris(return_X_y=True)\n",
    "X_train = X_dataset\n",
    "y_train = []\n",
    "for y in y_dataset:\n",
    "    y_train.append([y])\n",
    "print(y_train)\n",
    "iris_nn = NeuralNetwork(len(X_train[0]), 10, 1) # Mendefinisikan ukuran neural network\n",
    "iris_nn.train(X_train,y_train, activation_function=\"sigmoid\", error_treshold = 10)\n",
    "iris_nn.test(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
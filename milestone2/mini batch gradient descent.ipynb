{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tugas Besar Machine Learning Milestone 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                5.1               3.5                1.4               0.2\n",
       "1                4.9               3.0                1.4               0.2\n",
       "2                4.7               3.2                1.3               0.2\n",
       "3                4.6               3.1                1.5               0.2\n",
       "4                5.0               3.6                1.4               0.2"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets,model_selection,metrics,neural_network\n",
    "iris = datasets.load_iris()\n",
    "iris = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "iris.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "X_train = X\n",
    "y_train = y\n",
    "# print(y_train)\n",
    "# print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fungsi utilitas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(25)\n",
    "\n",
    "def rand(a, b):\n",
    "    return (b-a)*random.random() + a\n",
    "\n",
    "def makeMatrix(I, J, fill=0.0):\n",
    "    m = []\n",
    "    for i in range(I):\n",
    "        m.append([fill]*J)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fungsi-fungsi aktivasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(x):\n",
    "    return x\n",
    "\n",
    "def dlinear(y):\n",
    "    return 1.0\n",
    "\n",
    "def sigmoid(x):\n",
    "    return math.tanh(x)\n",
    "\n",
    "def dsigmoid(y):\n",
    "    return 1.0 - y**2\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0.0,x)\n",
    "\n",
    "def drelu(y):\n",
    "    if y > 0.0 :\n",
    "        return 1.0\n",
    "    else :\n",
    "        return 0.0\n",
    "\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x)\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "def dsoftmax(y):\n",
    "    \"\"\" \n",
    "    if( = targetclass):\n",
    "        return y\n",
    "    else:\n",
    "        return -1 #apalah \"\"\"\n",
    "    # \"diagonalise\" the array\n",
    "    y_diag = np.diag(y)\n",
    "    # make an array, each member of y spread across/horizontally\n",
    "    y_vector = y.reshape(y.shape[0], 1)\n",
    "    y_matrix = np.tile(y_vector, y.shape[0])\n",
    "    return y_diag - (y_matrix * np.transpose(y_matrix))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kelas Neural Network\n",
    "note : kode ditulis ulang dari milestone 1 karena representasi bobotnya terlalu susah buat dipake hitung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, ni, nh, no):\n",
    "        self.ni = ni + 1\n",
    "        self.nh = nh\n",
    "        self.no = no\n",
    "\n",
    "        self.ai = [1.0]*self.ni\n",
    "        self.ah = [1.0]*self.nh\n",
    "        self.ao = [1.0]*self.no\n",
    "\n",
    "        self.wi = makeMatrix(self.ni, self.nh)\n",
    "        self.wo = makeMatrix(self.nh, self.no)\n",
    "\n",
    "        self.activation_function = \"sigmoid\"\n",
    "\n",
    "        # init bobot neural network\n",
    "        for i in range(self.ni):\n",
    "            for j in range(self.nh):\n",
    "                self.wi[i][j] = rand(-0.4, 0.4)\n",
    "        for j in range(self.nh):\n",
    "            for k in range(self.no):\n",
    "                self.wo[j][k] = rand(-5.0, 5.0)\n",
    "\n",
    "\n",
    "    def activate(self, inputs):\n",
    "        assert len(inputs) == self.ni-1, \"masukan input salah\"\n",
    "\n",
    "        # aktivasi input layer\n",
    "        for i in range(self.ni-1):\n",
    "            self.ai[i] = inputs[i]\n",
    "\n",
    "        # aktivasi \n",
    "        for j in range(self.nh):\n",
    "            sum = 0.0\n",
    "            for i in range(self.ni):\n",
    "                sum = sum + self.ai[i] * self.wi[i][j]\n",
    "            self.ah[j] = sigmoid(sum)\n",
    "\n",
    "        # output activations\n",
    "        for k in range(self.no):\n",
    "            sum = 0.0\n",
    "            for j in range(self.nh):\n",
    "                sum = sum + self.ah[j] * self.wo[j][k]\n",
    "            self.ao[k] = sigmoid(sum)\n",
    "\n",
    "        return self.ao[:]\n",
    "\n",
    "\n",
    "    def backPropagate(self, targets, learning_rate, activation_function):\n",
    "        assert len(targets) == self.no, \"masukan target salah\"\n",
    "\n",
    "        output_deltas = [0.0] * self.no\n",
    "        for k in range(self.no):\n",
    "            error = targets[k]-self.ao[k]\n",
    "            output_deltas[k] = dsigmoid(self.ao[k]) * error\n",
    "\n",
    "        hidden_deltas = [0.0] * self.nh\n",
    "        for j in range(self.nh):\n",
    "            error = 0.0\n",
    "            for k in range(self.no):\n",
    "                error = error + output_deltas[k]*self.wo[j][k]\n",
    "            hidden_deltas[j] = dsigmoid(self.ah[j]) * error\n",
    "\n",
    "        for j in range(self.nh):\n",
    "            for k in range(self.no):\n",
    "                w_delta = output_deltas[k]*self.ah[j]\n",
    "                self.wo[j][k] = self.wo[j][k] + learning_rate*w_delta\n",
    "\n",
    "        for i in range(self.ni):\n",
    "            for j in range(self.nh):\n",
    "                w_delta = hidden_deltas[j]*self.ai[i]\n",
    "                self.wi[i][j] = self.wi[i][j] + learning_rate*w_delta\n",
    "\n",
    "        error = 0.0\n",
    "        if(activation_function != \"softmax\"):\n",
    "            for k in range(len(targets)):\n",
    "                error = error + 0.5*(targets[k]-self.ao[k])**2\n",
    "        else:\n",
    "            # error function softmax\n",
    "            for k in range(len(targets)):\n",
    "                error = error -log(softmax(targets[k]))\n",
    "        return error\n",
    "\n",
    "\n",
    "    def test(self, X_test):\n",
    "        for x in X_test:\n",
    "            print(x, '->', self.activate(x))\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        prediction = []\n",
    "        for i in range(len(X_test)):\n",
    "            prediction.append(self.activate(X_test[i]))\n",
    "        return prediction\n",
    "\n",
    "    def createMiniBatches(self, X_train, y_train, batch_size):\n",
    "        mini_batches = []\n",
    "        data = np.hstack((X_train, y_train))\n",
    "        np.random.shuffle(data)\n",
    "        n_minibatches = data.shape[0] // batch_size\n",
    "\n",
    "        for i in range(n_minibatches + 1):\n",
    "            mini_batch = data[i * batch_size:(i + 1)*batch_size, :]\n",
    "            X_mini = mini_batch[:, :-1]\n",
    "            Y_mini = mini_batch[:, -1].reshape((-1, 1))\n",
    "            mini_batches.append((X_mini, Y_mini))\n",
    "        if data.shape[0] % batch_size != 0:\n",
    "            mini_batch = data[i * batch_size:data.shape[0]]\n",
    "            X_mini = mini_batch[:, :-1]\n",
    "            Y_mini = mini_batch[:, -1].reshape((-1, 1))\n",
    "            mini_batches.append((X_mini, Y_mini))\n",
    "        return mini_batches\n",
    "\n",
    "    def train(self, X_train, y_train, iterations=30, learning_rate=0.01, error_treshold = 0.01, activation_function=\"sigmoid\", batch_size = 10):\n",
    "        # N: learning rate\n",
    "        self.activation_function = activation_function\n",
    "        for i in range(0, iterations):\n",
    "            error = 0.0\n",
    "            mini_batches = self.createMiniBatches(X_train, y_train, batch_size)\n",
    "            for mini_batch in mini_batches:\n",
    "                error = 0.0\n",
    "                for j in range(0, len(X_train)):\n",
    "                    inputs = X_train[j]\n",
    "                    targets = y_train[j]\n",
    "                    self.activate(inputs)\n",
    "                    error = error + self.backPropagate(targets, learning_rate, activation_function)\n",
    "\n",
    "                if i % 10 == 0:\n",
    "                    print('error %-.5f' % error)\n",
    "\n",
    "                if error < error_treshold:\n",
    "                    print('final error %-.5f' % error)\n",
    "                    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dataset, y_dataset = datasets.load_iris(return_X_y=True)\n",
    "X_train = X_dataset\n",
    "y_train = []\n",
    "for y in y_dataset:\n",
    "    y_train.append([y])\n",
    "print(y_train)\n",
    "iris_nn = NeuralNetwork(len(X_train[0]), 10, 1) # Mendefinisikan ukuran neural network\n",
    "iris_nn.train(X_train,y_train, activation_function=\"sigmoid\", error_treshold = 10)\n",
    "iris_nn.test(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = neural_network.MLPClassifier(random_state=1, max_iter=300).fit(X_train, y_train)\n",
    "clf.score(X_train, y_train)\n",
    "print(\"Accuracy score: %f\" % metrics.accuracy_score(y_train, clf.predict(X_train)))\n",
    "print(\"F1 Score : %f\" % metrics.f1_score(y_train, clf.predict(X_train),average='weighted'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
